# ğŸ§  Iris Extended Classification using Artificial Neural Networks (ANN)

## ğŸ“˜ Project Overview
This project uses an **Artificial Neural Network (ANN)** to classify flowers based on an **extended version of the Iris dataset**.  
The dataset includes both the original Iris features and additional engineered attributes such as petal/sepal ratios, area, curvature, and texture â€” making it a richer dataset for deep learning.

---

## ğŸ§© Objectives
- Perform **data preprocessing** (handle missing values, encode categories, treat outliers).
- Visualize feature distributions and skewness.
- Build and train an **Artificial Neural Network** for multi-class classification.
- Optimize hyperparameters using **Keras Tuner**.
- Deploy a user-friendly **Streamlit web app** for live predictions.

---

## ğŸ“‚ Project Structure
Iris-ANN/
â”‚
â”œâ”€â”€ iris_extended.csv # Dataset file
â”œâ”€â”€ app.py # Streamlit application
â”œâ”€â”€ best_ann_model.h5 # Trained ANN model
â”œâ”€â”€ scaler.pkl # Saved StandardScaler
â”œâ”€â”€ your_notebook.ipynb # Full preprocessing & training notebook
â”œâ”€â”€ ann_tuning/ # Hyperparameter tuning logs
â””â”€â”€ README.md # Project documentation


---

## âš™ï¸ Technologies Used
- **Python 3.10+**
- **TensorFlow / Keras**
- **Scikit-learn**
- **Matplotlib / Seaborn**
- **Pandas / NumPy**
- **Keras Tuner**
- **Streamlit** (for deployment)

---

## ğŸ”¬ Workflow Summary

### 1. **Data Preprocessing**
- Loaded the dataset using `pandas`.
- Encoded categorical columns (`species`, `soil_type`) using `LabelEncoder`.
- Applied log transformation to reduce skewness in selected columns.
- Detected and capped outliers using IQR method.
- Standardized numeric features using `StandardScaler`.

### 2. **Exploratory Data Analysis**
- Visualized feature distributions using histograms and KDE plots.
- Inspected outliers through boxplots before and after capping.

### 3. **Model Building**
- Designed an ANN with multiple hidden layers using `Sequential` API.
- Activation Functions: **ReLU**, **Softmax**.
- Loss Function: **Sparse Categorical Crossentropy**.
- Optimizer: **Adam**.

### 4. **Hyperparameter Tuning**
- Used **Keras Tuner (RandomSearch)** to tune:
  - Number of hidden layers  
  - Units per layer  
  - Dropout rate  
  - Activation function  
  - Learning rate
- Achieved accuracy close to **100%** on the test set.

## Streamlit Deployment
 Built an interactive web app to input feature values.

Scales user input and predicts flower species using the trained ANN model.
app("https://manosree30-iris-ann-app-vakpb1.streamlit.app/")

## Results

Successfully trained and optimized a deep learning model for multi-class flower classification.

Achieved ~100% test accuracy after hyperparameter tuning.

Created an end-to-end workflow â€” from preprocessing to web deployment.